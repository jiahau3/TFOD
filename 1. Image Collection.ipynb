{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\user\\miniconda3\\envs\\tfod\\lib\\site-packages (4.5.5.62)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from opencv-python) (1.21.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import opencv\n",
    "import cv2 \n",
    "\n",
    "# Import uuid\n",
    "import uuid\n",
    "\n",
    "# Import Operating System\n",
    "import os\n",
    "\n",
    "# Import time\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define Images to Collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['thumbsup', 'thumbsdown', 'peace', 'glasses']\n",
    "number_imgs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Setup Folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'collectedimages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(IMAGES_PATH):\n",
    "    if os.name == 'posix':\n",
    "        !mkdir -p {IMAGES_PATH}\n",
    "    if os.name == 'nt':\n",
    "         !mkdir {IMAGES_PATH}\n",
    "for label in labels:\n",
    "    path = os.path.join(IMAGES_PATH, label)\n",
    "    if not os.path.exists(path):\n",
    "        !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Capture Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for thumbsup\n",
      "Collecting image 0\n",
      "Collecting image 1\n",
      "Collecting image 2\n",
      "Collecting image 3\n",
      "Collecting image 4\n",
      "Collecting images for thumbsdown\n",
      "Collecting image 0\n",
      "Collecting image 1\n",
      "Collecting image 2\n",
      "Collecting image 3\n",
      "Collecting image 4\n",
      "Collecting images for peace\n",
      "Collecting image 0\n",
      "Collecting image 1\n",
      "Collecting image 2\n",
      "Collecting image 3\n",
      "Collecting image 4\n",
      "Collecting images for glasses\n",
      "Collecting image 0\n",
      "Collecting image 1\n",
      "Collecting image 2\n",
      "Collecting image 3\n",
      "Collecting image 4\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    cap = cv2.VideoCapture(0) # 0 for identifying the position of web camera\n",
    "    print('Collecting images for {}'.format(label))\n",
    "    time.sleep(5)\n",
    "    for imgnum in range(number_imgs):\n",
    "        print('Collecting image {}'.format(imgnum))\n",
    "        ret, frame = cap.read() # ret for indication of recieving frames\n",
    "        imgname = os.path.join(IMAGES_PATH,label,label+'.'+'{}.jpg'.format(str(uuid.uuid1())))\n",
    "        cv2.imwrite(imgname, frame)\n",
    "        cv2.imshow('frame', frame)\n",
    "        time.sleep(3)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Image Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyqt5\n",
      "  Using cached PyQt5-5.15.6-cp36-abi3-win_amd64.whl (6.7 MB)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.7.1-cp37-cp37m-win_amd64.whl (3.7 MB)\n",
      "     ---------------------------------------- 3.7/3.7 MB 2.2 MB/s eta 0:00:00\n",
      "Collecting PyQt5-Qt5>=5.15.2\n",
      "  Using cached PyQt5_Qt5-5.15.2-py3-none-win_amd64.whl (50.1 MB)\n",
      "Collecting PyQt5-sip<13,>=12.8\n",
      "  Downloading PyQt5_sip-12.9.1-cp37-cp37m-win_amd64.whl (76 kB)\n",
      "     ---------------------------------------- 76.9/76.9 KB 2.1 MB/s eta 0:00:00\n",
      "Installing collected packages: PyQt5-Qt5, PyQt5-sip, lxml, pyqt5\n",
      "Successfully installed PyQt5-Qt5-5.15.2 PyQt5-sip-12.9.1 lxml-4.7.1 pyqt5-5.15.6\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pyqt5 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELIMG_PATH = os.path.join('Tensorflow', 'labelimg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Tensorflow\\labelimg'...\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(LABELIMG_PATH):\n",
    "    !mkdir {LABELIMG_PATH}\n",
    "    !git clone https://github.com/tzutalin/labelImg {LABELIMG_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name == 'posix':\n",
    "    !make qt5py3\n",
    "if os.name =='nt':\n",
    "    !cd {LABELIMG_PATH} && pyrcc5 -o libs/resources.py resources.qrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cancel creation.\n",
      "Image:C:\\DS_projects\\TFOD\\Tensorflow\\workspace\\images\\collectedimages\\thumbsup\\thumbsup.21b39ac0-85a2-11ec-b1b4-a46bb617d477.jpg -> Annotation:C:/DS_projects/TFOD/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.21b39ac0-85a2-11ec-b1b4-a46bb617d477.xml\n",
      "Image:C:\\DS_projects\\TFOD\\Tensorflow\\workspace\\images\\collectedimages\\thumbsup\\thumbsup.33b66e46-85a2-11ec-abfe-a46bb617d477.jpg -> Annotation:C:/DS_projects/TFOD/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.33b66e46-85a2-11ec-abfe-a46bb617d477.xml\n",
      "Image:C:\\DS_projects\\TFOD\\Tensorflow\\workspace\\images\\collectedimages\\thumbsup\\thumbsup.254e50b1-85a2-11ec-b33e-a46bb617d477.jpg -> Annotation:C:/DS_projects/TFOD/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.254e50b1-85a2-11ec-b33e-a46bb617d477.xml\n",
      "Image:C:\\DS_projects\\TFOD\\Tensorflow\\workspace\\images\\collectedimages\\thumbsup\\thumbsup.23811029-85a2-11ec-83e1-a46bb617d477.jpg -> Annotation:C:/DS_projects/TFOD/Tensorflow/workspace/images/collectedimages/thumbsup/thumbsup.23811029-85a2-11ec-83e1-a46bb617d477.xml\n",
      "Image:C:\\DS_projects\\TFOD\\Tensorflow\\workspace\\images\\collectedimages\\thumbsdown\\thumbsdown.2c8124e8-85a2-11ec-978d-a46bb617d477.jpg -> Annotation:C:/DS_projects/TFOD/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.2c8124e8-85a2-11ec-978d-a46bb617d477.xml\n",
      "Cancel creation.\n",
      "Image:C:\\DS_projects\\TFOD\\Tensorflow\\workspace\\images\\collectedimages\\thumbsdown\\thumbsdown.301cf79b-85a2-11ec-8ef0-a46bb617d477.jpg -> Annotation:C:/DS_projects/TFOD/Tensorflow/workspace/images/collectedimages/thumbsdown/thumbsdown.301cf79b-85a2-11ec-8ef0-a46bb617d477.xml\n",
      "Image:C:\\DS_projects\\TFOD\\Tensorflow\\workspace\\images\\collectedimages\\peace\\peace.3e7d8ca9-85a2-11ec-a908-a46bb617d477.jpg -> Annotation:C:/DS_projects/TFOD/Tensorflow/workspace/images/collectedimages/peace/peace.3e7d8ca9-85a2-11ec-a908-a46bb617d477.xml\n",
      "Image:C:\\DS_projects\\TFOD\\Tensorflow\\workspace\\images\\collectedimages\\peace\\peace.404909ba-85a2-11ec-bfe6-a46bb617d477.jpg -> Annotation:C:/DS_projects/TFOD/Tensorflow/workspace/images/collectedimages/peace/peace.404909ba-85a2-11ec-bfe6-a46bb617d477.xml\n",
      "Image:C:\\DS_projects\\TFOD\\Tensorflow\\workspace\\images\\collectedimages\\glasses\\glasses.1e105d04-85a2-11ec-9e44-a46bb617d477.jpg -> Annotation:C:/DS_projects/TFOD/Tensorflow/workspace/images/collectedimages/glasses/glasses.1e105d04-85a2-11ec-9e44-a46bb617d477.xml\n",
      "Image:C:\\DS_projects\\TFOD\\Tensorflow\\workspace\\images\\collectedimages\\glasses\\glasses.1fe74f2f-85a2-11ec-b95f-a46bb617d477.jpg -> Annotation:C:/DS_projects/TFOD/Tensorflow/workspace/images/collectedimages/glasses/glasses.1fe74f2f-85a2-11ec-b95f-a46bb617d477.xml\n",
      "Image:C:\\DS_projects\\TFOD\\Tensorflow\\workspace\\images\\collectedimages\\glasses\\glasses.4b08b0eb-85a2-11ec-aed9-a46bb617d477.jpg -> Annotation:C:/DS_projects/TFOD/Tensorflow/workspace/images/collectedimages/glasses/glasses.4b08b0eb-85a2-11ec-aed9-a46bb617d477.xml\n",
      "Image:C:\\DS_projects\\TFOD\\Tensorflow\\workspace\\images\\collectedimages\\glasses\\glasses.4cd66ab8-85a2-11ec-a1aa-a46bb617d477.jpg -> Annotation:C:/DS_projects/TFOD/Tensorflow/workspace/images/collectedimages/glasses/glasses.4cd66ab8-85a2-11ec-a1aa-a46bb617d477.xml\n",
      "Image:C:\\DS_projects\\TFOD\\Tensorflow\\workspace\\images\\collectedimages\\glasses\\glasses.49397f1f-85a2-11ec-a775-a46bb617d477.jpg -> Annotation:C:/DS_projects/TFOD/Tensorflow/workspace/images/collectedimages/glasses/glasses.49397f1f-85a2-11ec-a775-a46bb617d477.xml\n",
      "Image:C:\\DS_projects\\TFOD\\Tensorflow\\workspace\\images\\collectedimages\\glasses\\glasses.50703ae3-85a2-11ec-94e6-a46bb617d477.jpg -> Annotation:C:/DS_projects/TFOD/Tensorflow/workspace/images/collectedimages/glasses/glasses.50703ae3-85a2-11ec-94e6-a46bb617d477.xml\n"
     ]
    }
   ],
   "source": [
    "!cd {LABELIMG_PATH} && python labelImg.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Move them into a Training and Testing Partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIONAL - 7. Compress them for Colab Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'train')\n",
    "TEST_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'test')\n",
    "ARCHIVE_PATH = os.path.join('Tensorflow', 'workspace', 'images', 'archive.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(TRAIN_PATH):\n",
    "    if os.name == 'posix':\n",
    "        !mkdir -p {TRAIN_PATH}\n",
    "    if os.name == 'nt':\n",
    "         !mkdir {TRAIN_PATH}\n",
    "if not os.path.exists(TEST_PATH):\n",
    "    if os.name == 'posix':\n",
    "        !mkdir -p {TEST_PATH}\n",
    "    if os.name == 'nt':\n",
    "        !mkdir {TEST_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tar: Tensorflow\\\\workspace\\\\images\\train: Cannot stat: No such file or directory\n",
      "tar: Tensorflow\\\\workspace\\\\images\\test: Cannot stat: No such file or directory\n",
      "tar: Exiting with failure status due to previous errors\n"
     ]
    }
   ],
   "source": [
    "!tar -czf {ARCHIVE_PATH} {TRAIN_PATH} {TEST_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
